\documentclass[12pt,a4paper]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\usepackage{subcaption}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{amsmath}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
%\SweaveOpts{concordance=TRUE}

\title{Sequential rank agreement methods for comparison of ranked lists}
\author{}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

Ranked lists occur in many applications of statistics. Regression
methods rank predictor variables according to magnitude of association
with outcome, prediction models rank subjects according to their risk
of an event, and genetic studies rank genes according to their
difference in expression across samples. A common research question is
where to stop, i.e., to decide the maximal significant rank.  In the
three examples this would correspond to the number of significantly
associated predictor variables, the number of patients at high risk of
an event, and the number of genes that are worth to pursue in further
experiments, respectively.

In this article we describe some new breakthrough tools for measuring
agreement across a set of lists which soon will enter the state-of-the
art. The methods should be useful whenever there are multiple rankings
of the same list. The idea is to define agreement based on the ranks
of the first k elements in each list.


\section{Methods}

Consider a set of $P$ different items $X=\{X_1,\dots,X_P\}$. An
ordered list is a permutation function, $R: \{1,\dots,P\}\to
\{1,\dots,P\}$, such that $R(X_p)$ is the rank of item $X_p$ in the
list. The inverse mapping $\pi=R^{-1}$ assigns to rank
$r\in\{1,\dots,P\}$ the item $\pi(r)$ found at that rank. The methods
described below work for a set of $L$ lists $R_1,\dots,R_L$,
$L\geq2$. We denote $\pi_l=R_l^{-1}$ for the corresponding inverse
mappings. Panels (a) and (b) of Table~\ref{tab:example} show a
schematic example of these mappings.

\begin{table}[tb]
  \caption{Example set of ranked lists. (a) shows the ranked list of items for each of three lists, (b) presents the ranks obtained by each item in each of the three lists and (c) shows the cumulative set of items up to a given depth in the three lists.}
\begin{center}
  \begin{subtable}{4cm}%
    \caption{}
      \begin{tabular}{cccc}
        \hline\hline % & \multicolumn{3}{c}{List} \\
        Rank & $\pi_1$ & $\pi_2$ & $\pi_3$ \\ \hline
        1 & A & A & B \\
        2 & B & C & A \\
        3 & C & D & E \\
        4 & D & B & C \\
        5 & E & E & D \\ \hline
    \end{tabular}
  \end{subtable}
% \hfill
\hspace{1em}
%%% 
  \begin{subtable}{4cm}%
    \caption{}
    \begin{tabular}{cccc} \hline\hline
  % & \multicolumn{3}{c}{List} \\
    Item & $R_1$ & $R_2$ & $R_3$ \\ \hline
    A & 1 & 1 & 2 \\
    B & 2 & 4 & 1 \\
    C & 3 & 2 & 4 \\
    D & 4 & 3 & 5 \\
    E & 5 & 5 & 3 \\ \hline
  \end{tabular}
\end{subtable}
% \hfill
\hspace{1em}
%%%
\begin{subtable}{4cm}%
  \caption{}
\begin{tabular}{cc} \hline\hline
% Depth   &     \\
Depth  &  $S_d$ \\ \hline
1 & $\{$A, B$\}$\\
2 & $\{$A, B, C$\}$ \\
3 & $\{$A, B, C, D, E$\}$ \\
4 & $\{$A, B, C, D, E$\}$ \\
5 & $\{$A, B, C, D, E$\}$ \\ \hline
\end{tabular}
\end{subtable}
\end{center}
\label{tab:example}
\end{table}

The agreement of the lists regarding the rank given to an item can be
measured by
\begin{equation}
  A(p) = f(R_1(p), \ldots, R_L(p)),
\end{equation}
for a distance function $f$. Throughout this paper we will use the
sample standard error as our function $f$ and hence use
$$A(p) = \sqrt{\frac{\sum_{i=1}^L (R_i(p) - \bar{R}(p))^2}{L-1}},
$$
but other choices could be made (see the discussion). The sample
standard error has an interpretation as the average distance of the
individual rankings of the lists from the average ranking.

We now describe what is exemplified in Panel (c) of Table
\ref{tab:example} and how it can be used to define \emph{sequential
  rank agreement}. For an integer $1\le d\le P$ we define the unique
set of items found in the $L$ top $d$ parts of the lists, i.e., the
set of items ranked less than or equal to $d$ in any of the lists:
\begin{equation}
S_d = \{\pi_l(r) ; r \leq d, l = 1, \ldots, L \}.
\end{equation}
The \emph{sequential rank agreement} is the pooled standard deviation
of the items found in the set $S_d$:
\begin{equation}
\textrm{SRA}(d)= \sqrt{\frac{\sum_{\{p \in S_d\}}(L-1)A(p)^2}{(L-1)|S_d|}}.
\end{equation}

\subsection{All lists fully observed}
We shall start by the simplest case where all $L$ lists are fully observed. 

\subsection{Analysis of top $k$ lists}
Not uncommon for lists to be 


censored


Let $\Lambda_l, l=1, \ldots, L$ be the set of items found in list $l$
so $\Lambda_l$ is the top $k_l$ list of items from list $l$ where $k_l
= |\Lambda_l|$. Note that we observe the top $k$ items for each of the
$L$ lists if $k_1=\cdots=k_L=k$. For censored lists the rank function
becomes
\begin{equation}
\tilde R_l(p) = \left\{\begin{array}{cl} \{\pi_l^{-1}(p)\} & \text{ for } p\in \Lambda_l \\ 
\{k_l+1,\dots,P\} & \text{ for } p \not\in \Lambda_l\end{array}\right.
\end{equation}
where we only know that the rank for the unobserved items in list $l$ must be larger than the largest rank observed in that list.

In the case of censored lists it is sufficient (FIXME: requires
argument) to look at depths where we have corresponding observations
so the largest rank we should consider will be
\begin{equation}
d \leq \max(k_1, \ldots, k_L).
\end{equation}

We cannot directly compute $A(p)$ for all predictors because we only observe a censored version of $\tilde R$ for some of the lists. Instead we assume that the rank assigned to predictor $p$ in list $l$ is uniformly distributed among the ranks that have been unassigned for list $l$. The ranks are clearly not independent since each of the lists essentially contains full set of ranks 

\begin{equation}
\tilde A(p) = \frac{\sum_{r_1; r_1\in \tilde R_1(p)}  \cdots \sum_{r_L; r_L\in \tilde R_L(p)} A(p)}{\prod_l |\tilde R_l(p)|}
\end{equation}

FIXME: If instead of running through all elements of $\tilde R_1(p)$
one would use the average rank in $\tilde R_1(p)$ we would end up with
a too small variance.

\section{Benchmarks}

\section{Applications}

\subsection{Evaluating results from top-$k$ lists}

\subsection{Comparing results across different method}

\subsection{Stability of results}

Bootstrap across a single method and compare results. Discuss collinearity

\section{Discussion}

Mention/discuss different measures. 

\end{document}
