\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[]{color}
\usepackage{subcaption}
\usepackage{natbib}
\usepackage{xspace}
\usepackage{calc}
\usepackage[noae]{Sweave}
\usepackage{authblk}
\usepackage{algorithm}
\usepackage{algpseudocode}
%
% New commands
%
\newcommand{\ie}{\emph{i.e.}\@\xspace}
\newcommand{\eg}{\emph{e.g.}\@\xspace}

\SweaveOpts{prefix.string=paper, keep.source=TRUE}

%%% RSS specific items



\title{Sequential rank agreement methods for comparison of ranked
  lists}
\author{Claus Thorn Ekstrøm}
\author{Thomas Alexander Gerds}
\author{Kasper Brink-Jensen}
\affil{Biostatistics, University of Copenhagen}



\begin{document}

% Use square brackets for numbering affiliations

\maketitle

\begin{abstract}
  The comparison of ranked lists has been studied for several decades
  but since the advent of large data types it has received increased
  interest. Computer science and genomics are just two areas that need
  to compare ranked lists in order to in- vestigate similarities
  between different analytical methods. Often the aim is to find a
  measure of similarity for two or more ordered lists that comprise
  the first k items from each list. Since ordered lists typically are
  more similar at the top of the list another approach, which is taken
  in this paper is to ask: for how long are the lists highly similar?
  Using terminology from agreement analysis we derive the measure
  depth of agreement using the standard deviation of the ranks, a
  method that both provides an intuitive interpretation and can be
  applied to any number of lists even if these are incomplete. The
  finding are illustrated using simulations and applied to a publicly
  available cancer dataset.
\end{abstract}

Key words: sequential rank agreement, top lists, rank agreement, order statistic,
methods comparison, variable selection

Multiple lists. Weigh top over bottom. Censoring. Interpretation

\section{Introduction}

Ranking of items or results is common in scientific research and
ranked lists occur as the result of many applications in
statistics. Regression methods rank predictor variables according to
magnitude of association with outcome, prediction models rank subjects
according to their risk of an event, and genetic studies rank genes
according to their difference in gene expression levels across
samples.

When several ranked lists are available a common research question is
to what extent the lists agree on the ranking. In other words: is it
possible to decide on a optimal rank until which the lists agree on
the items?  A typical situation would arise in high-dimensional
genomics studies where several analysis methods had been applied to a
dataset or where a literature search provided differing tables of,
say, top 10 lists of the most important genes associated to an
outcome.  Similarly, this would correspond to the number of associated
predictor variables that are found consistently over the lists, the
number of patients at high risk of an event in all lists, and the
number of genes that are worth to pursue in further experiments in the
three examples above, respectively.

The analysis of rankings is hardly new, and several other approaches
have proposed a measure of the ``distance'' between two ranked
lists. Of these, Kendall's $\tau$
%\citep{kendall1948}
and Spearman’s footrule
%$\rho$ \citep{Spearman1910}
are the most well-known. Both measure the similarity of two ranked
lists but neither of them make any distinction between errors towards
the top versus the errors towards the bottom of the lists.  Several
modified versions of Kendall's $\tau$ and Spearman's footrule have been
proposed. \citet{Shieh1998} proposed a weighted $\tau$ where each pair
of rankings can be assigned different weights, and \citet{Yilmaz2008}
proposed the $\tau_{ap}$ which places higher emphasis on the top of
the lists.
%
Spearman’s footrule use the ranks of the variables for calculation of
the distance and the use of ranks are also employed in the $M$
measure of \citet{Bar-Ilan2006} where the reciprocal rank differences
are used to calculate the similarity measure.

More recent approaches consider the intersection of lists as the basis
for a similarity measure. However, simple intersections also places
equal weights on all depths of the list which led \citet{Fagin2003}
and \citet{Webber2010} to modify the simple intersection to put more
emphasis on the top of the lists by using the cumulative intersection
divided by the depth as their similarity measures (denoted the average
overlap (AO)). \citet{Webber2010} define their rank-biased overlap
(RBO) by weighting with a converging series thus ensuring the top is
always weighted higher than the (potentially indefinite) bottom of the
lists.  While it is possible to calculate measures that describe how
similar lists are at a given depth with some of the methods described
above, the interpretation of the measures is unclear --- especially
with multiple lists --- and it is difficult to identify a depth at
which the lists are no longer similar.


In this article we propose a method to measure similarity among ranked
lists for each depth in the list. As a measure for similarity we will
use the limits of agreement known from agreement between quantitative
variables \citep{Carstensen2010} but will compute the agreement on the
ranks of the items.  The proposed method allows for multiple lists
simultaneously, provides a dynamic measure of agreement for each depth
in the lists, places more weight on the top of the list, accommodates
censored/incomplete lists of varying lengths, and has a natural
interpretation that directly relates to the ranks. The general idea is
to define agreement based on the sequence of ranks from the first $k$
elements in each list. This approach allows us to estimate a potential
change point in the agreement in order to determine an optimal $k$
where there is a shift in the agreement among lists and enables us to
use randomization approaches to evaluate the rank agreement. In this
sense it is a combination and generalization of some of the ideas of
\citet{Carterette2009} and \citet{Boulesteix2009}. The former compares
two rankings based on the distance between them as measured by a
multivariate Gaussian distribution and the latter presents an overview
of approaches for aggregation of ranked lists including bootstrap and
leave-one-out jackknife approaches.




The manuscript is organized as follows: In the next section we will
define the sequential rank agreement among multiple ranked lists and
discuss how to handle incomplete/censored lists. In section 3 we
present and discuss approaches to evaluate the sequential rank
agreement obtained from an experiment and to identify the optimal
depth $k$ for which the ranked lists agree. Finally we present three
quite different applications of the proposed sequential rank agreement
approach to real data before we discuss the findings along with
possible extensions.



<<echo=FALSE>>=
#note: always pass alpha on the 0-255 scale
makeTransparent<-function(someColor, alpha=100)
{
  newColor<-col2rgb(someColor)
  apply(newColor, 2, function(curcoldata){rgb(red=curcoldata[1], green=curcoldata[2],
    blue=curcoldata[3],alpha=alpha, maxColorValue=255)})
}
@ %

\section{Methods}

Consider a set of $P$ different items $X=\{X_1,\dots,X_P\}$. An
ordered list is a permutation function, $R: \{X_1,\dots,X_P\}\to
\{1,\dots,P\}$, such that $R(X_p)$ is the rank of item $X_p$ in the
list. The inverse mapping $\pi=R^{-1}$ assigns to rank
$r\in\{1,\dots,P\}$ the item $\pi(r)$ found at that rank. The methods
described below work for a set of $L$ lists $R_1,\dots,R_L$,
$L\geq2$. We denote $\pi_l=R_l^{-1}$ for the corresponding inverse
mappings. Panels (a) and (b) of Table~\ref{tab:example} show a
schematic example of these mappings. Thus if $\pi_l(1)=X_{34}$ then
item $X_{34}$ is ranked first in list $l$, and similarly $R_l(X_{34})=1$.

\begin{table}[tb]
  \caption{Example set of ranked lists. (a) shows the ranked list of items for each of three lists, (b) presents the ranks obtained by each item in each of the three lists and (c) shows the cumulative set of items up to a given depth in the three lists.}
\begin{center}
  \begin{subtable}{4cm}%
    \caption{}
      \begin{tabular}{cccc}
        \hline\hline % & \multicolumn{3}{c}{List} \\
        Rank & $\pi_1$ & $\pi_2$ & $\pi_3$ \\ \hline
        1 & A & A & B \\
        2 & B & C & A \\
        3 & C & D & E \\
        4 & D & B & C \\
        5 & E & E & D \\ \hline
    \end{tabular}
  \end{subtable}
% \hfill
\hspace{1em}
%%%
  \begin{subtable}{4cm}%
    \caption{}
    \begin{tabular}{cccc} \hline\hline
  % & \multicolumn{3}{c}{List} \\
    Item & $R_1$ & $R_2$ & $R_3$ \\ \hline
    A & 1 & 1 & 2 \\
    B & 2 & 4 & 1 \\
    C & 3 & 2 & 4 \\
    D & 4 & 3 & 5 \\
    E & 5 & 5 & 3 \\ \hline
  \end{tabular}
\end{subtable}
% \hfill
\hspace{1em}
%%%
\begin{subtable}{4cm}%
  \caption{}
\begin{tabular}{cc} \hline\hline
% Depth   &     \\
Depth  &  $S_d$ \\ \hline
1 & $\{$A, B$\}$\\
2 & $\{$A, B, C$\}$ \\
3 & $\{$A, B, C, D, E$\}$ \\
4 & $\{$A, B, C, D, E$\}$ \\
5 & $\{$A, B, C, D, E$\}$ \\ \hline
\end{tabular}
\end{subtable}
\end{center}
\label{tab:example}
\end{table}

The agreement of the lists regarding the rank given to an item $X_p$ can be
measured by
\begin{equation}
  A(X_p) = f(R_1(X_p), \ldots, R_L(X_p)),
\end{equation}
for a distance function $f$. Throughout this paper we will use the
sample standard error as our function $f$ and hence use
$$A(X_p) = \sqrt{\frac{\sum_{i=1}^L (R_i(X_p) - \bar{R}(X_p))^2}{L-1}},
$$
but other choices could be made (see the discussion). The sample
standard error has an interpretation as the average distance of the
individual rankings of the lists from the average ranking.

We now describe what is exemplified in Panel (c) of Table
\ref{tab:example} and how it can be used to define \emph{sequential
  rank agreement}. For an integer $1\le d\le P$ we define the unique
set of items found in the $L$ top $d$ parts of the lists, i.e., the
set of items ranked less than or equal to $d$ in any of the lists:
\begin{equation}
S_d = \{\pi_l(r) ; r \leq d, l = 1, \ldots, L \}.
\end{equation}
The \emph{sequential rank agreement} is the pooled standard deviation
of the items found in the set $S_d$:
\begin{equation}
\textrm{SRA}(d)= \sqrt{\frac{\sum_{\{p \in
      S_d\}}(L-1)A(X_p)^2}{(L-1)|S_d|}}, \label{def:sra}
\end{equation}
and small values close to zero suggests that the lists agree on the
ordering while larger values suggests disagreement. If the ranked
lists are identical then the value of SRA will be zero for all depths
$d$.  The sequential rank agreement can be interpreted as the average
distance of the individual rankings of the lists from the average
ranking for each of the items we have seen until depth $d$.


\subsection{Agreement among fully observed lists}
The simplest case occurs when all $L$ lists are fully
observed, \ie, we have observed the rank of all $P$ items for all $L$
lists. Fully observed ranked lists are common and arise, for example,
when different statistical analysis methods are applied to a single
dataset to produce lists of predictors ranked according to their
importance, or if the same analysis method is applied to data from
different populations.

With fully observed lists we can plot the sequential rank agreement
\eqref{def:sra} as a function of depth $d$.  An example is seen in the
left panel of Figure~\ref{fig:example1} where four analysis methods
were used to rank genes (for further detail see the application
section below). The sequential rank agreement at depth $d$ can be
interpreted as how many ranks apart do we on average expect the items
found until depth $d$ to be so smaller values on the $y$ axis
correspond to better agreement among the lists than larger values.

If the lists generally agree on all items then we expect the
sequential rank agreement curve to be flat, but if there are changes
in the levels of rank agreement then this suggests that there are sets
of items that the lists agree on and other sets where they rank the
items differently. In particular, we generally expect the agreement
among the lists to be better towards the top of the lists and worse
towards the end of the lists, and in this case the sequential rank
agreement curve will start at a low level, and then have an increase
before it levels off.


\begin{figure}[tb]
\begin{center}
\includegraphics[width=.45\textwidth]{paper-fig1a}
\includegraphics[width=.45\textwidth]{paper-fig1b}
\end{center}
 \caption{Left panel: Sequential rank agreement for 4 different analysis methods
   applied to the 3051 genes in the Golub data (solid line). The dashed line shows the
   corresponding estimated sequential rank agreement for censored
   lists based purely on the top 50 ranked genes. Right panel contains
   the same information but has zoomed in on the first part of the $x$-axis.}
 \label{fig:example1}
\end{figure}


\subsection{Analysis of incomplete/censored lists}
Incomplete lists are also a common occurrence that arise from, for
example, comparison of top $k$ lists, or when some methods only rank a
subset of the items (e.g., penalized regression based on the Lasso provides a
sparse set of predictors that have non-zero coefficients. There is no
obvious ordering of the predictors that have all been shrunk to zero).

Sequential rank agreement can be generalized to incomplete/censored
lists in the following way.  Let $\Lambda_l, l=1, \ldots, L$ be the
set of items found in list $l$ so $\Lambda_l$ is the top $k_l$ list of
items from list $l$ where $k_l = |\Lambda_l|$. Note that if
$k_1=\cdots=k_L=k$ then we observe the top $k$ items for each of the
$L$ lists. For censored lists the rank function becomes
\begin{equation}
\tilde R_l(X_p) = \left\{\begin{array}{cl} \{\pi_l^{-1}(p)\} & \text{ for } p\in \Lambda_l \\
\{k_l+1,\dots,P\} & \text{ for } p \not\in \Lambda_l\end{array}\right.
\end{equation}
where we only know that the rank for the unobserved items in list $l$
must be larger than the largest rank observed in that list.
Unless we have additional prior knowledge about the distribution of the
unranked items then we can restrict attention of the sequential rank
agreement to
\begin{equation}
d \leq \max(k_1, \ldots, k_L),
\end{equation}
since we have no information about the ordering of the items after a
depth $d$ where all lists are censored.

The agreement, $A(X_p)$, cannot be computed directly for all
predictors because we only observe the censored version of $R(X_p)$
for some of the lists. Instead we assume that the rank assigned to
item $X_p$ in list $l$ is uniformly distributed among the ranks that
have \emph{not} been assigned for list $l$. The algorithm is described
in detail in Algorithm~\ref{sra-algorithm}.


%, so the augmented agreement
%becomes
%\begin{equation}
%\bar{A}(X_p) = \frac{\sum_{r_1; r_1\in \tilde R_1(X_p)}  \cdots
%  \sum_{r_L; r_L\in \tilde R_L(X_p)} A(X_p)}{\prod_l |\tilde
%  R_l(X_p)|}. \label{formula:censored-agreement}
%\end{equation}
%Similarly, the sequential rank agreement becomes
%\begin{equation}
%XXX \textrm{SRA}(d)= \sqrt{\frac{\sum_{\{p \in S_d\}}(L-1)\tilde{A}(X_p)^2}{(L-1)|S_d|}}, \label{def:sra-censored}
%\end{equation}

The rankings within a single list are clearly not independent since
each rank must appear exactly in each list. Thus, by randomizing
unobserved items as described in \eqref{formula:censored-agreement}



\begin{algorithm}
\caption{Sequential rank agreement algorithm for censored lists}
\label{sra-algorithm}
\begin{algorithmic}[1]
\Procedure{Censored rank agreement}{}
\State Let $B$ be the number of permutations to use
\For{each $b \in B$}
\For{each censored list $l \in L$}
\State \parbox[t]{\dimexpr\linewidth-\algorithmicindent-1.7cm}{Permute the unassigned ranks, $k_l+1, \ldots, P$ and assign
them randomly to the items \emph{not} found in the list, i.e.,
$\Lambda^\complement$, in order to fill out the lists.}
\EndFor
\State \parbox[t]{\dimexpr\linewidth-\algorithmicindent-1cm}{Let sra($b$) be the sequential rank agreement computed from the
filled out lists.}
\EndFor
\State Return element-wise averages across all $B$ permutations of sra($b$).
\EndProcedure
\end{algorithmic}
\end{algorithm}




 ess contains full set of ranks and by using
the ... instead of applying the average ...

the mean then we

FIXME: If instead of running through all elements of $\tilde R_1(X_p)$
one would use the average rank in $\tilde R_1(X_p)$ we would end up with
a too small variance.

FIXME: For censored lists we expect a change point around the depth
where the lists are censored. This is an artefact stemming from the
fact that

\section{Evaluating sequential rank agreement}

To interpretate the sequential rank agreement scale we propose by
several different benchmark values. Our data free benchmark value is
obtained by computing the sequential rank agreement of $L$ lists each
containing a permutation of $P$ items. Practically this benchmark
value can be obtained by averaging the result of repeated computer
experiments. In the uncensored case each experiment contains $L$ lists
of random permutations of the numbers $1,\dots,P$. In the censored
case only the uncensored part of the orginal lists is randomly
permuted.

In our experience XX repetitions are sufficient to reduce Monte Carlo
error. Table Appendix A shows benchmark values obtained with

Our no-information benchmark can be applied in situations where each
list is an importance ranking of $P$ predictors resulting from
regression analyses. The idea is to repeat the regression analyses in
modified data where the outcome vector is randomly permuted. This
artificially removes any potential information regarding the
regression that the real data may contain.

- third approach?

\subsection{Independent lists}

\subsection{Permuted outcomes + analyses}

Do the following a large number of times
\begin{enumerate}
  \item Permute outcome vector
  \item Redo analyses for all $L$ methods
  \item Compute sequential rank agreement for
\end{enumerate}

Lidt spøjs ting man matcher dem op imod

\subsection{Changepoint analysis}

\section{Applications}

\subsection{Comparing results across different method}

In a classical paper by \citet{Golub1999} a dataset of 3051 gene
expression values were measured on 38 tumor mRNA samples in order to
improve the classification of acute leukemias between two types: acute
lymphoblastic leukemia (ALL) or acute myeloid leukemia
(AML). Preprocessing of the gene expression data was done as described
in \citep{Dudoit2002}.

We analyzed these gene expression data using four different
approaches: marginal two-sample $t$ tests, marginal logistic
regression analyses, logistic regression eleastic net, and marginal
maximum information content correlations (MIC) \citep{Reshef2011}. For
the first two methods, the genes were ranked according to $p$ value.


<<example1, echo=FALSE>>=
library(SuperRanker)
library(glmnet)
library(minerva)
library(changepoint)
library(randomForestSRC)

# Read data
library(multtest)
data(golub)


y <- golub.cl
x <- golub

producelists <- function(x, y) {
    nitems <- nrow(x)
    index <- seq(1, nrow(golub))
                                        # d <- data.frame(y, x)

                                        # Marginale t-tests
    mt.p <- sapply(index, function(i) { t.test(x[i,] ~ y)$p.value } )
    list1 <- order(mt.p)

                                        # Marginale logreg-tests
    mlogreg.p <- sapply(index, function(i) { drop1(glm(y ~ x[i,], family=binomial), test="Chisq")[2,5] } )
    list2 <- order(mlogreg.p)

                                        # Elastic net
    X <- scale(t(x))
    enet <- glmnet(X, y, family="binomial", alpha=.8)
    nyres <- cv.glmnet(X, y, family="binomial", alpha=.8)
    coefficients <- coef(enet, s=nyres$lambda.1se)[-1]
    nonzeros <- sum(coefficients!=0)
    list3 <- order(abs(coefficients), decreasing=TRUE)
    if (nonzeros<nitems) {
        list3[(nonzeros+1):nitems] <- NA
    }
                                        # MIC
    MIC <- sapply(index, function(i) { mine(x[i,], y)$MIC})
    list4 <- order(MIC, decreasing=TRUE)


                                        # Random Forest
###    dd <- data.frame(y=factor(y), t(x))
                                        # dd <- data.frame(y=y, t(x))
###    f1 <- rfsrc(y ~ ., data=dd, ntree=100)
###    variables <- abs(f1$importance[,1])
###    num.undecided <- sum(variables==0)
###    list5 <- order(variables, decreasing=TRUE)
###    list5[(length(variables)-num.undecided):length(variables)] <- 0

    cbind(list1,list2,list3,list4)
}

inputmatrix <- producelists(x, y)
colnames(inputmatrix) <- c("T", "LogReg", "ElasticNet", "MIC", "RF")[1:ncol(inputmatrix)]

res <- sqrt(sra(inputmatrix, B=20))
inputmatrix2 <- inputmatrix
inputmatrix2[51:nrow(inputmatrix),] <- NA
res2 <- sqrt(sra(inputmatrix2, B=20))

@


<<fig1a, fig=TRUE,echo=FALSE,include=FALSE>>=
ysize <- 1000
plot(res[1:ysize], lwd=3, col="red", type="l", ylim=c(0,1300), ylab="Sequential rank agreement", xlab="Depth")
lines(res2[1:ysize], lwd=2, col="purple")

@ %

<<fig1b, fig=TRUE,echo=FALSE,include=FALSE >>=
ysize <- 80
plot(res[1:ysize], lwd=3, col="red", type="l", ylim=c(0,1300), ylab="Sequential rank agreement", xlab="Depth")
lines(res2[1:ysize], lwd=2, col="purple")


@ %




<<fig2a, fig=TRUE,echo=FALSE,include=FALSE,cache=TRUE>>=
ysize <- 1000
plot(res[1:ysize], lwd=3, col="red", type="l", ylim=c(0,1300), ylab="Sequential rank agreement", xlab="Depth")
lines(res2[1:ysize], lwd=2, col="purple")
##
# col1 <- makeTransparent()
null <- sqrt(random_list_sra(inputmatrix, B=1, n=40))
null3 <- sqrt(random_list_sra(inputmatrix, B=20, n=20))
## matlines(null[1:ysize,], col="gray", lty=1)

##

##null2 <- sapply(1:40, function(i) {
##    sra(producelists(x, sample(y)), B=1)
##} )
## matlines(null2[1:ysize,], col="lightblue", lty=1)

load("R/fig1null.rda")

bcolor <- makeTransparent("lightblue", alpha=80)
bcolor2 <- makeTransparent("red", alpha=80)
bcolor3 <- makeTransparent("green", alpha=80)


www <- smooth_sra(null2)
polygon(c(1:length(www$lower), rev(1:length(www$lower))),
        c(www$lower, rev(www$upper)),
        col=bcolor, border=NA)

www <- smooth_sra(null)
polygon(c(1:length(www$lower), rev(1:length(www$lower))),
        c(www$lower, rev(www$upper)),
        col=bcolor2, border=NA)

www <- smooth_sra(null3)
polygon(c(1:length(www$lower), rev(1:length(www$lower))),
        c(www$lower, rev(www$upper)),
        col=bcolor3, border=NA)



@ %

<<fig2b, fig=TRUE,echo=FALSE,include=FALSE,cache=TRUE >>=
ysize <- 80
plot(res[1:ysize], lwd=3, col="red", type="l", ylim=c(0,1300), ylab="Sequential rank agreement", xlab="Depth")
lines(res2[1:ysize], lwd=2, col="purple")
##
# col1 <- makeTransparent()
null <- sqrt(random_list_sra(inputmatrix, B=1, n=400))
null3 <- sqrt(random_list_sra(inputmatrix, B=20, n=200))
## matlines(null[1:ysize,], col="gray", lty=1)

##

##null2 <- sapply(1:40, function(i) {
##    sra(producelists(x, sample(y)), B=1)
##} )
## matlines(null2[1:ysize,], col="lightblue", lty=1)

load("R/fig1null.rda")

bcolor <- makeTransparent("lightblue", alpha=80)
bcolor2 <- makeTransparent("red", alpha=80)
bcolor3 <- makeTransparent("green", alpha=80)


www <- smooth_sra(null2)
polygon(c(1:length(www$lower), rev(1:length(www$lower))),
        c(www$lower, rev(www$upper)),
        col=bcolor, border=NA)

www <- smooth_sra(null)
polygon(c(1:length(www$lower), rev(1:length(www$lower))),
        c(www$lower, rev(www$upper)),
        col=bcolor2, border=NA)

www <- smooth_sra(null3)
polygon(c(1:length(www$lower), rev(1:length(www$lower))),
        c(www$lower, rev(www$upper)),
        col=bcolor3, border=NA)



@ %



\begin{figure}[tb]
\begin{center}
\includegraphics[width=.45\textwidth]{paper-fig2a}
\includegraphics[width=.45\textwidth]{paper-fig2b}
\end{center}
 \caption{Sequential rank agreement for 4 different analysis methods
   applied to the Golub data (thick red line). The red and blue shaded
 areas represent the pointwise 95\% normal areas for the XXX and XXY benchmarks,
respectively.}
 \label{fig:case1}
\end{figure}

<<label=tab1,echo=FALSE,results=tex>>=
library(xtable)
xxx <- as.data.frame(inputmatrix[1:10,])
xxx2 <- xtable(xxx)
digits(xxx2) <- 0
print(xxx2)
#print(xtable(xxx, caption = "Top 10 list of results", label = "tab:one",
#digits = c(0, 0, 2, 0, 2, 3, 3)), table.placement = "tbp",
#caption.placement = "top")

@



<<>>=
library(changepoint)
cp1 <- cpt.mean(res, method="BinSeg")
cp2 <- cpt.mean(res2, method="BinSeg")
cp1@cpts
cp1@param.est
cp2@cpts
cp2@param.est
@

\subsection{Stability of results}

\subsection{Evaluating results from top-$k$ lists}



Bootstrap across a single method and compare results. Discuss collinearity


\section{Comparison to ...}

The overlap among $L$ lists observed until depth $d$ is defined as the
proportion of items that are found in all $L$ lists compared to the
possible number of items found in all lists observed until depth $d$:
\begin{equation}
O(d) = \frac{| \cap_{l=1}^L \{\pi_l(r); r\leq d \} |}{d}.
\end{equation}
Typically, the overlap is only considered for pairwise comparisons

The average overlap at depth $d$ is defined as the average of the
overlaps until $d$,
\begin{equation}
AO(d) = \sum_{i=1}^d \frac{O(d)}{d}.
\end{equation}
This definition indirectly ensures that extra emphasis is included on
the top of the list since the items



In this section we apply the method to the ColonData data from the R
package MAMA (Ihnatova, 2013), which consists of gene expression
measurements from a subset of 500 genes from 77 individuals from
Denmark, 36 from Australia and 41 from Japan as well as information on
microsattelite stability (stable MSS/unstable MSI) which is often used
as an indicator for colorectal cancer. The genes were tested for
difference in expression in the MSI/MSS groups using the limma package
(Smyth, 2005). The genes were then ranked according to p–values giving
three lists that we wish to compare, the top of these can be seen in
Table 4.


<<fig-ao1, echo=FALSE, fig=TRUE,include=FALSE>>=
myres <- average_overlap(inputmatrix[,1:2])
myres2 <- average_overlap(inputmatrix[-c(1,2),1:2])
xvals <- 1:500
plot(myres, xlim=c(1, 300), ylim=c(0,1), type="l")
lines(xvals[-c(1,2)], myres2[1:498], col="red")
@ 

<<fig-ao2, echo=FALSE, fig=TRUE,include=FALSE>>=
mmyres <- sqrt(sra(inputmatrix[,1:2]))
mmyres2 <- sqrt(sra(inputmatrix[-c(1,2),1:2]))
xvals <- 1:500
plot(mmyres, xlim=c(1, 300), ylim=c(0,1), type="l")
lines(xvals[-c(1,2)], mmyres2[1:498], col="red")
@ 



\begin{figure}[tb]
\begin{center}
\includegraphics[width=.45\textwidth]{paper-fig-ao1}
\includegraphics[width=.45\textwidth]{paper-fig-ao2}
\end{center}
 \caption{Sequential rank agreement for 4 different analysis methods
   applied to the Golub data (thick red line). The red and blue shaded
 areas represent the pointwise 95\% normal areas for the XXX and XXY benchmarks,
respectively.}
 \label{fig:case1}
\end{figure}



\section{Discussion}

Mention/discuss different measures.


\bibliographystyle{rss}
\bibliography{paperref}

\end{document}



